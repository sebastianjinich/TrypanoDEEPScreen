{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.datamodule import DEEPscreenDataModule\n",
    "from engine.system import DEEPScreenClassifier\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.lightning import RayDDPStrategy, RayLightningEnvironment, RayTrainReportCallback, prepare_trainer\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import MedianStoppingRule\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "import os\n",
    "from utils.configurations import configs\n",
    "\n",
    "\n",
    "class deepscreen_hyperparameter_tuneing:\n",
    "    def __init__(self,data:pd.DataFrame,search_space:dict,target:str,data_split_mode:str=\"non_random_split\",grace_period:int=90,metric:str=\"val_mcc\",mode:str=\"max\",num_workers:int=1,num_samples:int=10,experiments_result_path=\"../../.experiments/\"):\n",
    "\n",
    "        self.data = data\n",
    "        self.search_space = search_space\n",
    "        self.num_samples =  num_samples\n",
    "        self.target = target\n",
    "        self.data_split_mode = data_split_mode\n",
    "        self.experiment_result_path = os.path.join(experiments_result_path,self.target)\n",
    "        if not os.path.exists(self.experiment_result_path):\n",
    "                os.makedirs(self.experiment_result_path)\n",
    "\n",
    "        self.scheduler = MedianStoppingRule(\n",
    "            time_attr=\"training_iteration\",\n",
    "            metric=metric,\n",
    "            mode=mode,\n",
    "            grace_period=grace_period # number of epochs to wait to stop trianing if median mcc is not better\n",
    "            )\n",
    "        \n",
    "        self.scaling_config = ScalingConfig(\n",
    "            num_workers=num_workers, use_gpu=True, resources_per_worker={\"CPU\": 1, \"GPU\": 1}\n",
    "            )\n",
    "\n",
    "        self.run_config = RunConfig(\n",
    "            checkpoint_config=CheckpointConfig(\n",
    "                num_to_keep=2,\n",
    "                checkpoint_score_attribute=metric,\n",
    "                checkpoint_score_order=mode,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "        self.ray_trainer = TorchTrainer(\n",
    "            self._train_func,\n",
    "            scaling_config=self.scaling_config,\n",
    "            run_config=self.run_config,\n",
    "        )\n",
    "\n",
    "    def _train_func(self,config):\n",
    "        dm = DEEPscreenDataModule(\n",
    "             data=self.data,\n",
    "             target_id=self.target,\n",
    "             batch_size=config[\"batch_size\"],\n",
    "             experiment_result_path=self.experiment_result_path,\n",
    "             data_split_mode=self.data_split_mode,\n",
    "             tmp_imgs=configs.get_use_tmp_imgs())\n",
    "        model = DEEPScreenClassifier(**config,experiment_result_path=self.experiment_result_path)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            devices=\"auto\",\n",
    "            accelerator=\"auto\",\n",
    "            strategy=RayDDPStrategy(),\n",
    "            callbacks=[RayTrainReportCallback()],\n",
    "            plugins=[RayLightningEnvironment()],\n",
    "            enable_progress_bar=False,\n",
    "        )\n",
    "        trainer = prepare_trainer(trainer)\n",
    "        trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    def tune_deepscreen(self):\n",
    "\n",
    "        tuner = tune.Tuner(\n",
    "            self.ray_trainer,\n",
    "            param_space={\"train_loop_config\": self.search_space},\n",
    "            tune_config=tune.TuneConfig(\n",
    "                num_samples=self.num_samples,\n",
    "                scheduler=self.scheduler,\n",
    "            ),\n",
    "        )\n",
    "        return tuner.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../.data/processed/CHEMBL5567.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_deepscreen = {\n",
    "        'fully_layer_1': tune.choice([16, 32, 128, 256, 512]),\n",
    "        'fully_layer_2': tune.choice([16, 32, 128, 256, 512]),\n",
    "        'learning_rate': tune.choice([0.0005, 0.0001, 0.005, 0.001, 0.01]),\n",
    "        'batch_size': tune.choice([32, 64]),\n",
    "        'drop_rate': tune.choice([0.5, 0.6, 0.8]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 17:05:26,571\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "2024-02-08 17:05:27,554\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2024-02-08 17:05:27,557\tINFO tune.py:583 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You passed a `metric` or `mode` argument to `Tuner(...)`, but the scheduler you are using was already instantiated with their own `metric` and `mode` parameters. Either remove the arguments from your scheduler or from `Tuner(...)` args.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tuner \u001b[38;5;241m=\u001b[39m deepscreen_hyperparameter_tuneing(data,search_space_deepscreen,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchembl5567\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_deepscreen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m, in \u001b[0;36mdeepscreen_hyperparameter_tuneing.tune_deepscreen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_deepscreen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mray_trainer,\n\u001b[1;32m     72\u001b[0m         param_space\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loop_config\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_space},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m         ),\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/big/lab/sjinich/venv_che/lib/python3.8/site-packages/ray/tune/tuner.py:381\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_ray_client:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TuneError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\n\u001b[1;32m    384\u001b[0m             _TUNER_FAILED_MSG\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    385\u001b[0m                 path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_tuner\u001b[38;5;241m.\u001b[39mget_experiment_checkpoint_dir()\n\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/big/lab/sjinich/venv_che/lib/python3.8/site-packages/ray/tune/impl/tuner_internal.py:509\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m param_space \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_space)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_restored:\n\u001b[0;32m--> 509\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resume(trainable, param_space)\n",
      "File \u001b[0;32m/big/lab/sjinich/venv_che/lib/python3.8/site-packages/ray/tune/impl/tuner_internal.py:628\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fitting for a fresh Tuner.\"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuner_kwargs,\n\u001b[1;32m    627\u001b[0m }\n\u001b[0;32m--> 628\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_remote_string_queue()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis\n",
      "File \u001b[0;32m/big/lab/sjinich/venv_che/lib/python3.8/site-packages/ray/tune/tune.py:865\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    854\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed a `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_space_arg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` parameter to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    855\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentrypoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem in the search algorithm\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms search space if necessary.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheduler_set_search_props(\n\u001b[1;32m    863\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mset_search_properties, metric, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexperiments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpublic_spec\n\u001b[1;32m    864\u001b[0m ):\n\u001b[0;32m--> 865\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed a `metric` or `mode` argument to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentrypoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe scheduler you are using was already instantiated with their \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mown `metric` and `mode` parameters. Either remove the arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom your scheduler or from `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentrypoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` args.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m progress_metrics \u001b[38;5;241m=\u001b[39m _detect_progress_metrics(_get_trainable(run_or_experiment))\n\u001b[1;32m    875\u001b[0m air_usage\u001b[38;5;241m.\u001b[39mtag_storage_type(experiments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstorage)\n",
      "\u001b[0;31mValueError\u001b[0m: You passed a `metric` or `mode` argument to `Tuner(...)`, but the scheduler you are using was already instantiated with their own `metric` and `mode` parameters. Either remove the arguments from your scheduler or from `Tuner(...)` args."
     ]
    }
   ],
   "source": [
    "tuner = deepscreen_hyperparameter_tuneing(data,search_space_deepscreen,\"chembl5567\")\n",
    "tuner.tune_deepscreen()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
