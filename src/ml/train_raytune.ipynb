{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.datamodule import DEEPscreenDataModule\n",
    "from engine.system import DEEPScreenClassifier\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.lightning import RayDDPStrategy, RayLightningEnvironment, RayTrainReportCallback, prepare_trainer\n",
    "from ray import tune\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.search.bohb import TuneBOHB\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.tune import CLIReporter\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch import seed_everything\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from utils.configurations import configs\n",
    "from utils.constants import RANDOM_STATE\n",
    "from datasets.datamodule import DEEPscreenDataModule\n",
    "from engine.system import DEEPScreenClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class deepscreen_hyperparameter_tuneing:\n",
    "    def __init__(self,data:pd.DataFrame,search_space:dict,target:str,max_epochs:int = 200,data_split_mode:str=\"non_random_split\",scheduler_type = \"BOHB\", grace_period:int=90,metric:str=\"val_mcc\",mode:str=\"max\",num_workers:int=1,num_samples:int=10,experiments_result_path=\"../../.experiments/\"):\n",
    "        seed_everything(RANDOM_STATE,True)\n",
    "\n",
    "        self.data = data\n",
    "        self.search_space = search_space\n",
    "        self.num_samples =  num_samples\n",
    "        self.target = target\n",
    "        self.data_split_mode = data_split_mode\n",
    "        self.experiment_path = experiments_result_path\n",
    "        self.experiment_result_path = os.path.join(experiments_result_path,self.target)\n",
    "        self.max_epochs = max_epochs\n",
    "        if not os.path.exists(self.experiment_result_path):\n",
    "                os.makedirs(self.experiment_result_path)\n",
    "        self.use_gpu = configs.get_gpu_number() > 0\n",
    "\n",
    "        self.scheduler = HyperBandForBOHB(\n",
    "                            time_attr=\"training_iteration\",\n",
    "                            max_t=self.max_epochs,\n",
    "                            reduction_factor=3,\n",
    "                            stop_last_trials=True,\n",
    "                        )\n",
    "        \n",
    "        self.scaling_config = ScalingConfig(\n",
    "            num_workers=1, use_gpu=self.use_gpu, resources_per_worker={\"CPU\": configs.get_cpu_number(), \"GPU\": configs.get_gpu_number()}\n",
    "            )\n",
    "        \n",
    "        self.search_algorithm = TuneBOHB()\n",
    "\n",
    "        self.run_config = RunConfig(\n",
    "            stop={\"training_iteration\": self.max_epochs},\n",
    "            checkpoint_config=CheckpointConfig(\n",
    "                num_to_keep=2,\n",
    "                checkpoint_score_attribute=metric,\n",
    "                checkpoint_score_order=mode,\n",
    "                \n",
    "            ),\n",
    "            progress_reporter=CLIReporter(max_column_length=10,max_report_frequency=15)\n",
    "            )\n",
    "\n",
    "        self.ray_trainer = TorchTrainer(\n",
    "            self._train_func,\n",
    "            scaling_config=self.scaling_config,\n",
    "            run_config=self.run_config,\n",
    "        )\n",
    "\n",
    "    def _train_func(self,config):\n",
    "        dm = DEEPscreenDataModule(\n",
    "             data=self.data,\n",
    "             target_id=self.target,\n",
    "             batch_size=config[\"batch_size\"],\n",
    "             experiment_result_path=self.experiment_result_path,\n",
    "             data_split_mode=self.data_split_mode,\n",
    "             tmp_imgs=configs.get_use_tmp_imgs())\n",
    "        model = DEEPScreenClassifier(**config,experiment_result_path=self.experiment_result_path)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            devices=\"auto\",\n",
    "            accelerator=\"auto\",\n",
    "            strategy=RayDDPStrategy(),\n",
    "            callbacks=[RayTrainReportCallback()],\n",
    "            plugins=[RayLightningEnvironment()],\n",
    "            deterministic=True,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "        )\n",
    "        trainer = prepare_trainer(trainer)\n",
    "        trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    def tune_deepscreen(self):\n",
    "\n",
    "        tuner = tune.Tuner(\n",
    "            self.ray_trainer,\n",
    "            param_space={\"train_loop_config\": self.search_space},\n",
    "            tune_config=tune.TuneConfig(\n",
    "                num_samples=self.num_samples,\n",
    "                scheduler=self.scheduler,\n",
    "                search_alg=self.search_algorithm\n",
    "            ),\n",
    "        )\n",
    "        return tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "2024-02-08 21:16:26,085\tINFO tune.py:583 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:16:26 (running for 00:00:00.22)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:16:41 (running for 00:00:15.31)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:16:56 (running for 00:00:30.40)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:17:11 (running for 00:00:45.49)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:17:26,489\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:17:26 (running for 00:01:00.60)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:17:41 (running for 00:01:15.68)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:17:56 (running for 00:01:30.78)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:18:11 (running for 00:01:45.87)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:18:26,554\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:18:27 (running for 00:02:00.96)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:18:42 (running for 00:02:16.05)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:18:57 (running for 00:02:31.14)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:19:12 (running for 00:02:46.23)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:19:26,620\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:19:27 (running for 00:03:01.33)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:19:42 (running for 00:03:16.42)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:19:57 (running for 00:03:31.51)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:20:12 (running for 00:03:46.60)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:20:26,689\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:20:27 (running for 00:04:01.70)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:20:42 (running for 00:04:16.79)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:20:57 (running for 00:04:31.88)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:21:13 (running for 00:04:46.97)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:21:26,755\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:21:28 (running for 00:05:02.07)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:21:43 (running for 00:05:17.15)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:21:58 (running for 00:05:32.25)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:22:13 (running for 00:05:47.33)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:22:26,815\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:22:28 (running for 00:06:02.43)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:22:43 (running for 00:06:17.52)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:22:58 (running for 00:06:32.61)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:23:13 (running for 00:06:47.69)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:23:26,873\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:23:28 (running for 00:07:02.79)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:23:43 (running for 00:07:17.87)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:23:59 (running for 00:07:32.97)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:24:14 (running for 00:07:48.06)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:24:26,936\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:24:29 (running for 00:08:03.15)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:24:44 (running for 00:08:18.24)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:24:59 (running for 00:08:33.33)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:25:14 (running for 00:08:48.42)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:25:26,997\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:25:29 (running for 00:09:03.51)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:25:44 (running for 00:09:18.60)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:25:59 (running for 00:09:33.63)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:26:14 (running for 00:09:48.72)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:26:27,093\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:26:29 (running for 00:10:03.81)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:26:45 (running for 00:10:18.90)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:27:00 (running for 00:10:33.99)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:27:15 (running for 00:10:49.08)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:27:27,149\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:27:30 (running for 00:11:04.17)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:27:45 (running for 00:11:19.25)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:28:00 (running for 00:11:34.34)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:28:15 (running for 00:11:49.43)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:28:27,201\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:28:30 (running for 00:12:04.52)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:28:45 (running for 00:12:19.61)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:29:00 (running for 00:12:34.70)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:29:15 (running for 00:12:49.79)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:29:27,262\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:29:30 (running for 00:13:04.88)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:29:46 (running for 00:13:19.97)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:30:01 (running for 00:13:35.06)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:30:16 (running for 00:13:50.15)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:30:27,318\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:30:31 (running for 00:14:05.24)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:30:46 (running for 00:14:20.33)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:31:01 (running for 00:14:35.42)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:31:16 (running for 00:14:50.51)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:31:27,371\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:31:31 (running for 00:15:05.59)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:31:46 (running for 00:15:20.69)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:32:01 (running for 00:15:35.77)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:32:16 (running for 00:15:50.86)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:32:27,427\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:32:32 (running for 00:16:05.95)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:32:47 (running for 00:16:21.04)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:33:02 (running for 00:16:36.13)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:33:17 (running for 00:16:51.22)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:33:27,483\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:33:32 (running for 00:17:06.31)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:33:47 (running for 00:17:21.40)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:34:02 (running for 00:17:36.49)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:34:17 (running for 00:17:51.58)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:34:27,543\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:34:32 (running for 00:18:06.67)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:34:47 (running for 00:18:21.76)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:35:02 (running for 00:18:36.85)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:35:18 (running for 00:18:51.94)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:35:27,597\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:35:33 (running for 00:19:07.03)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:35:48 (running for 00:19:22.12)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:36:03 (running for 00:19:37.19)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:36:18 (running for 00:19:52.28)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:36:27,635\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:36:33 (running for 00:20:07.37)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:36:48 (running for 00:20:22.45)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:37:03 (running for 00:20:37.54)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:37:18 (running for 00:20:52.63)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:37:27,684\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:37:33 (running for 00:21:07.72)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:37:48 (running for 00:21:22.81)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:38:03 (running for 00:21:37.89)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:38:19 (running for 00:21:52.98)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:38:27,735\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:38:34 (running for 00:22:08.08)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:38:49 (running for 00:22:23.17)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:39:04 (running for 00:22:38.25)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:39:19 (running for 00:22:53.34)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:39:27,795\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:39:34 (running for 00:23:08.43)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:39:49 (running for 00:23:23.52)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:40:04 (running for 00:23:38.61)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:40:19 (running for 00:23:53.70)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:40:27,848\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:40:34 (running for 00:24:08.79)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:40:49 (running for 00:24:23.88)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:41:05 (running for 00:24:38.97)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:41:20 (running for 00:24:54.06)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:41:27,906\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 49.0 CPUs and 0 GPUs per trial, but the cluster only has 48.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:41:35 (running for 00:25:09.15)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-02-08 21:41:50 (running for 00:25:24.24)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 21:41:54,262\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-02-08 21:41:54,280\tINFO tune.py:1042 -- Total run time: 1528.19 seconds (1528.16 seconds for the tuning loop).\n",
      "2024-02-08 21:41:54,282\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\", trainable=...)\n",
      "2024-02-08 21:41:54,296\tWARNING experiment_analysis.py:193 -- Failed to fetch metrics for 10 trial(s):\n",
      "- TorchTrainer_515e0_00000: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00000: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00000_0_batch_size=32,drop_rate=0.6000,fully_layer_1=128,fully_layer_2=512,learning_rate=0.0050_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00001: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00001: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00001_1_batch_size=64,drop_rate=0.8000,fully_layer_1=256,fully_layer_2=128,learning_rate=0.0010_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00002: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00002: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00002_2_batch_size=32,drop_rate=0.6000,fully_layer_1=32,fully_layer_2=16,learning_rate=0.0001_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00003: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00003: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00003_3_batch_size=64,drop_rate=0.8000,fully_layer_1=16,fully_layer_2=16,learning_rate=0.0001_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00004: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00004: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00004_4_batch_size=32,drop_rate=0.6000,fully_layer_1=512,fully_layer_2=16,learning_rate=0.0005_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00005: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00005: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00005_5_batch_size=64,drop_rate=0.8000,fully_layer_1=256,fully_layer_2=128,learning_rate=0.0100_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00006: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00006: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00006_6_batch_size=64,drop_rate=0.6000,fully_layer_1=512,fully_layer_2=16,learning_rate=0.0005_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00007: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00007: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00007_7_batch_size=32,drop_rate=0.8000,fully_layer_1=256,fully_layer_2=512,learning_rate=0.0100_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00008: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00008: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00008_8_batch_size=64,drop_rate=0.5000,fully_layer_1=32,fully_layer_2=256,learning_rate=0.0050_2024-02-08_21-16-26')\n",
      "- TorchTrainer_515e0_00009: FileNotFoundError('Could not fetch metrics for TorchTrainer_515e0_00009: both result.json and progress.csv were not found at /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26/TorchTrainer_515e0_00009_9_batch_size=64,drop_rate=0.5000,fully_layer_1=16,fully_layer_2=256,learning_rate=0.0050_2024-02-08_21-16-26')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-02-08 21:41:54 (running for 00:25:28.16)\n",
      "Using MedianStoppingRule: num_stopped=0.\n",
      "Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
      "Result logdir: /home/sjinich/ray_results/TorchTrainer_2024-02-08_21-16-26\n",
      "Number of trials: 10/10 (10 PENDING)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../.data/processed/CHEMBL5567.csv\")\n",
    "search_space_deepscreen = {\n",
    "        'fully_layer_1': tune.choice([16, 32, 128, 256, 512]),\n",
    "        'fully_layer_2': tune.choice([16, 32, 128, 256, 512]),\n",
    "        'learning_rate': tune.choice([0.0005, 0.0001, 0.005, 0.001, 0.01]),\n",
    "        'batch_size': tune.choice([32, 64]),\n",
    "        'drop_rate': tune.choice([0.5, 0.6, 0.8]),\n",
    "    }\n",
    "tuner = deepscreen_hyperparameter_tuneing(data,search_space_deepscreen,\"chembl5567\",num_workers=2)\n",
    "result = tuner.tune_deepscreen()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
