{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/big/lab/sjinich/che_env/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "2024-03-14 21:12:34,949\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-14 21:12:35,177\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from engine.ensamble_model_train import deepscreen_ensamble\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>bioactivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL104783</td>\n",
       "      <td>COc1ccc(CN[C@@H](C(=O)N[C@H](C(=O)NCc2ccccc2)C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL104966</td>\n",
       "      <td>CC(C)[C@H](NC(=O)[C@H](NCc1ccccc1)[C@H](O)[C@H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL1076901</td>\n",
       "      <td>CC(C)[C@H](NC(=O)[C@H](C)C[C@H](O)[C@H](COCc1c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL1076902</td>\n",
       "      <td>CC(C)[C@H](NC(=O)[C@H](C)C[C@H](O)[C@H](COCc1c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL1076905</td>\n",
       "      <td>CC(C)[C@H](NC(=O)[C@H](C)C[C@H](O)[C@H](COc1cc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>CHEMBL96943</td>\n",
       "      <td>C=CC1C=CC=CC1/C=C/OCC(=O)NC(C(=O)NC(Cc1ccccc1)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>CHEMBL97013</td>\n",
       "      <td>CCCCNC(=O)CC(O)C(CC(C)C)NC(=O)C(NC(=O)Cc1ccc2c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>CHEMBL97072</td>\n",
       "      <td>C=Cc1ccccc1/C=C/OCC(=O)NC(C(=O)NC(CC(C)C)C(O)C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>CHEMBL97805</td>\n",
       "      <td>CCCCNC(=O)CC(O)C(CC(C)C)NC(=O)C(NC(=O)Cc1cc(OC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>CHEMBL98384</td>\n",
       "      <td>CCCCNC(=O)C[C@H](O)[C@H](Cc1ccccc1)NC(=O)[C@@H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2270 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            comp_id                                             smiles  \\\n",
       "0      CHEMBL104783  COc1ccc(CN[C@@H](C(=O)N[C@H](C(=O)NCc2ccccc2)C...   \n",
       "1      CHEMBL104966  CC(C)[C@H](NC(=O)[C@H](NCc1ccccc1)[C@H](O)[C@H...   \n",
       "2     CHEMBL1076901  CC(C)[C@H](NC(=O)[C@H](C)C[C@H](O)[C@H](COCc1c...   \n",
       "3     CHEMBL1076902  CC(C)[C@H](NC(=O)[C@H](C)C[C@H](O)[C@H](COCc1c...   \n",
       "4     CHEMBL1076905  CC(C)[C@H](NC(=O)[C@H](C)C[C@H](O)[C@H](COc1cc...   \n",
       "...             ...                                                ...   \n",
       "2265    CHEMBL96943  C=CC1C=CC=CC1/C=C/OCC(=O)NC(C(=O)NC(Cc1ccccc1)...   \n",
       "2266    CHEMBL97013  CCCCNC(=O)CC(O)C(CC(C)C)NC(=O)C(NC(=O)Cc1ccc2c...   \n",
       "2267    CHEMBL97072  C=Cc1ccccc1/C=C/OCC(=O)NC(C(=O)NC(CC(C)C)C(O)C...   \n",
       "2268    CHEMBL97805  CCCCNC(=O)CC(O)C(CC(C)C)NC(=O)C(NC(=O)Cc1cc(OC...   \n",
       "2269    CHEMBL98384  CCCCNC(=O)C[C@H](O)[C@H](Cc1ccccc1)NC(=O)[C@@H...   \n",
       "\n",
       "      bioactivity  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "2265            1  \n",
       "2266            1  \n",
       "2267            1  \n",
       "2268            1  \n",
       "2269            1  \n",
       "\n",
       "[2270 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antibioticos = pd.read_csv(\"/home/sjinich/disco/TrypanoDEEPscreen/.data/processed/CHEMBL2581.csv\")\n",
    "antibioticos = antibioticos[[\"comp_id\",\"smiles\",\"bioactivity\"]]\n",
    "antibioticos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "hpams = {\n",
    "    \"fully_layer_1\": 32, \"fully_layer_2\": 256, \"drop_rate\": 0.3, \"learning_rate\": 0.001, \"batch_size\": 32\n",
    "}\n",
    "ensamble = deepscreen_ensamble(\"antibioticos_ensamble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: trining ensamble model with dataset train: 1816|844/972 - validation: 454|212/242\n",
      "Missing logger folder: /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble/lighting_logs/lightning_logs\n",
      "INFO: Using a total of 2270 datapoints\n",
      "INFO: non_random_split dataset splited train=1816\n",
      "INFO: non_random_split dataset splited validation=454\n",
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble exists and is not empty.\n",
      "\n",
      "   | Name          | Type             | Params\n",
      "----------------------------------------------------\n",
      "0  | conv1         | Conv2d           | 416   \n",
      "1  | bn1           | BatchNorm2d      | 64    \n",
      "2  | conv2         | Conv2d           | 8.3 K \n",
      "3  | bn2           | BatchNorm2d      | 128   \n",
      "4  | conv3         | Conv2d           | 32.9 K\n",
      "5  | bn3           | BatchNorm2d      | 256   \n",
      "6  | conv4         | Conv2d           | 32.8 K\n",
      "7  | bn4           | BatchNorm2d      | 128   \n",
      "8  | conv5         | Conv2d           | 8.2 K \n",
      "9  | bn5           | BatchNorm2d      | 64    \n",
      "10 | pool          | MaxPool2d        | 0     \n",
      "11 | fc1           | Linear           | 25.6 K\n",
      "12 | fc2           | Linear           | 8.4 K \n",
      "13 | fc3           | Linear           | 514   \n",
      "14 | train_metrics | MetricCollection | 0     \n",
      "15 | val_metrics   | MetricCollection | 0     \n",
      "16 | test_metrics  | MetricCollection | 0     \n",
      "----------------------------------------------------\n",
      "117 K     Trainable params\n",
      "0         Non-trainable params\n",
      "117 K     Total params\n",
      "0.471     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 57/57 [00:34<00:00,  1.66it/s, v_num=0, train_loss=0.586]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:211: You called `self.log('val_mcc', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/57 [00:00<?, ?it/s, v_num=0, train_loss=0.586, val_loss=0.436]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  82%|████████▏ | 47/57 [00:25<00:05,  1.84it/s, v_num=0, train_loss=0.577, val_loss=2.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:211: You called `self.log('train_mcc', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:36<00:00,  1.56it/s, v_num=0, train_loss=0.217, val_loss=6.650] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:36<00:00,  1.56it/s, v_num=0, train_loss=0.217, val_loss=6.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Ensamble model trained 0/4 - path /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble/epoch=35-step=2052.ckpt\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: trining ensamble model with dataset train: 1816|844/972 - validation: 454|212/242\n",
      "INFO: Using a total of 2270 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: non_random_split dataset splited train=1816\n",
      "INFO: non_random_split dataset splited validation=454\n",
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble exists and is not empty.\n",
      "\n",
      "   | Name          | Type             | Params\n",
      "----------------------------------------------------\n",
      "0  | conv1         | Conv2d           | 416   \n",
      "1  | bn1           | BatchNorm2d      | 64    \n",
      "2  | conv2         | Conv2d           | 8.3 K \n",
      "3  | bn2           | BatchNorm2d      | 128   \n",
      "4  | conv3         | Conv2d           | 32.9 K\n",
      "5  | bn3           | BatchNorm2d      | 256   \n",
      "6  | conv4         | Conv2d           | 32.8 K\n",
      "7  | bn4           | BatchNorm2d      | 128   \n",
      "8  | conv5         | Conv2d           | 8.2 K \n",
      "9  | bn5           | BatchNorm2d      | 64    \n",
      "10 | pool          | MaxPool2d        | 0     \n",
      "11 | fc1           | Linear           | 25.6 K\n",
      "12 | fc2           | Linear           | 8.4 K \n",
      "13 | fc3           | Linear           | 514   \n",
      "14 | train_metrics | MetricCollection | 0     \n",
      "15 | val_metrics   | MetricCollection | 0     \n",
      "16 | test_metrics  | MetricCollection | 0     \n",
      "----------------------------------------------------\n",
      "117 K     Trainable params\n",
      "0         Non-trainable params\n",
      "117 K     Total params\n",
      "0.471     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 57/57 [00:29<00:00,  1.94it/s, v_num=1, train_loss=0.496]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/57 [00:00<?, ?it/s, v_num=1, train_loss=0.496, val_loss=0.673]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:36<00:00,  1.57it/s, v_num=1, train_loss=0.147, val_loss=1.020] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:36<00:00,  1.57it/s, v_num=1, train_loss=0.147, val_loss=1.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Ensamble model trained 1/4 - path /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble/epoch=44-step=2565.ckpt\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: trining ensamble model with dataset train: 1816|848/968 - validation: 454|208/246\n",
      "INFO: Using a total of 2270 datapoints\n",
      "INFO: non_random_split dataset splited train=1816\n",
      "INFO: non_random_split dataset splited validation=454\n",
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble exists and is not empty.\n",
      "\n",
      "   | Name          | Type             | Params\n",
      "----------------------------------------------------\n",
      "0  | conv1         | Conv2d           | 416   \n",
      "1  | bn1           | BatchNorm2d      | 64    \n",
      "2  | conv2         | Conv2d           | 8.3 K \n",
      "3  | bn2           | BatchNorm2d      | 128   \n",
      "4  | conv3         | Conv2d           | 32.9 K\n",
      "5  | bn3           | BatchNorm2d      | 256   \n",
      "6  | conv4         | Conv2d           | 32.8 K\n",
      "7  | bn4           | BatchNorm2d      | 128   \n",
      "8  | conv5         | Conv2d           | 8.2 K \n",
      "9  | bn5           | BatchNorm2d      | 64    \n",
      "10 | pool          | MaxPool2d        | 0     \n",
      "11 | fc1           | Linear           | 25.6 K\n",
      "12 | fc2           | Linear           | 8.4 K \n",
      "13 | fc3           | Linear           | 514   \n",
      "14 | train_metrics | MetricCollection | 0     \n",
      "15 | val_metrics   | MetricCollection | 0     \n",
      "16 | test_metrics  | MetricCollection | 0     \n",
      "----------------------------------------------------\n",
      "117 K     Trainable params\n",
      "0         Non-trainable params\n",
      "117 K     Total params\n",
      "0.471     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 57/57 [00:32<00:00,  1.78it/s, v_num=2, train_loss=0.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/57 [00:00<?, ?it/s, v_num=2, train_loss=0.460, val_loss=0.478]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:35<00:00,  1.59it/s, v_num=2, train_loss=0.132, val_loss=0.366] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:35<00:00,  1.59it/s, v_num=2, train_loss=0.132, val_loss=0.366]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Ensamble model trained 2/4 - path /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble/epoch=41-step=2394.ckpt\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: trining ensamble model with dataset train: 1816|849/967 - validation: 454|207/247\n",
      "INFO: Using a total of 2270 datapoints\n",
      "INFO: non_random_split dataset splited train=1816\n",
      "INFO: non_random_split dataset splited validation=454\n",
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble exists and is not empty.\n",
      "\n",
      "   | Name          | Type             | Params\n",
      "----------------------------------------------------\n",
      "0  | conv1         | Conv2d           | 416   \n",
      "1  | bn1           | BatchNorm2d      | 64    \n",
      "2  | conv2         | Conv2d           | 8.3 K \n",
      "3  | bn2           | BatchNorm2d      | 128   \n",
      "4  | conv3         | Conv2d           | 32.9 K\n",
      "5  | bn3           | BatchNorm2d      | 256   \n",
      "6  | conv4         | Conv2d           | 32.8 K\n",
      "7  | bn4           | BatchNorm2d      | 128   \n",
      "8  | conv5         | Conv2d           | 8.2 K \n",
      "9  | bn5           | BatchNorm2d      | 64    \n",
      "10 | pool          | MaxPool2d        | 0     \n",
      "11 | fc1           | Linear           | 25.6 K\n",
      "12 | fc2           | Linear           | 8.4 K \n",
      "13 | fc3           | Linear           | 514   \n",
      "14 | train_metrics | MetricCollection | 0     \n",
      "15 | val_metrics   | MetricCollection | 0     \n",
      "16 | test_metrics  | MetricCollection | 0     \n",
      "----------------------------------------------------\n",
      "117 K     Trainable params\n",
      "0         Non-trainable params\n",
      "117 K     Total params\n",
      "0.471     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 57/57 [00:32<00:00,  1.76it/s, v_num=3, train_loss=0.463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/57 [00:00<?, ?it/s, v_num=3, train_loss=0.463, val_loss=0.594]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:35<00:00,  1.60it/s, v_num=3, train_loss=0.372, val_loss=0.258] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 57/57 [00:35<00:00,  1.60it/s, v_num=3, train_loss=0.372, val_loss=0.258]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Ensamble model trained 3/4 - path /big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble/epoch=36-step=2109.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<lightning.pytorch.trainer.trainer.Trainer at 0x7f9bf9d5eac0>,\n",
       " <lightning.pytorch.trainer.trainer.Trainer at 0x7f9bf9973310>,\n",
       " <lightning.pytorch.trainer.trainer.Trainer at 0x7f9bf33caac0>,\n",
       " <lightning.pytorch.trainer.trainer.Trainer at 0x7f9bf3279ac0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensamble.fit(antibioticos,hpams,number_to_ensamble=4,max_epochs=50,metric_to_optimize=\"val_mcc\",optimize_mode=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = pd.read_csv(\"/home/sjinich/disco/TrypanoDEEPscreen/.data/processed/antibiotics_test_predict.csv\")\n",
    "data_pred[\"label\"] = data_pred[\"Pred_Score\"].str.replace(\",\",\".\").astype(float).round().astype(int)\n",
    "data_pred = pd.concat([data_pred.head(60),data_pred.tail(40)])\n",
    "data_test = data_pred[[\"comp_id\",\"smiles\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using a total of 100 datapoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using a total of 100 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using a total of 100 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using a total of 100 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  5.50it/s]\n"
     ]
    }
   ],
   "source": [
    "test, prediction  = ensamble.test(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load models and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/big/lab/sjinich/che_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/big/lab/sjinich/che_env/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "2024-03-15 13:21:17,692\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-15 13:21:17,916\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "from engine.ensamble_model_train import deepscreen_ensamble\n",
    "import pandas as pd\n",
    "\n",
    "ensamble = deepscreen_ensamble(\"antibioticos_ensamble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n",
      "INFO: Using hyperparameters [('fully_layer_1', 32), ('fully_layer_2', 256), ('drop_rate', 0.3), ('learning_rate', 0.001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble'), ('target', 'antibioticos_ensamble')]\n"
     ]
    }
   ],
   "source": [
    "ensamble.load_models(\"/home/sjinich/disco/TrypanoDEEPscreen/.experiments/antibioticos_ensamble/ensamble\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
