{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjinich/disco/che_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-27 16:42:28,272\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-06-27 16:42:28,372\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "# External imports\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "from torchmetrics import classification, MetricCollection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Internal imports\n",
    "from utils.configurations import configs\n",
    "from utils.logging_deepscreen import logger\n",
    "\n",
    "class DEEPScreenClassifier(L.LightningModule):\n",
    "    def __init__(self,fully_layer_1, fully_layer_2, drop_rate, learning_rate, batch_size, experiment_result_path, target):\n",
    "        super(DEEPScreenClassifier, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        logger.info(f\"Using hyperparameters {[i for i in self.hparams.items()]}\") \n",
    "\n",
    "        # Model architecture\n",
    "        self.conv1 = nn.Conv2d(3, 32, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 64, 2)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 32, 2)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(1010, fully_layer_1)\n",
    "        self.fc2 = nn.Linear(fully_layer_1, fully_layer_2)\n",
    "        self.fc3 = nn.Linear(fully_layer_2, 2)\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "        # Object atributes\n",
    "        self.config = configs\n",
    "        \n",
    "        # Performance trackers\n",
    "        self.train_metrics = MetricCollection(\n",
    "             {\n",
    "                \"train_acc\": classification.BinaryAccuracy(threshold=0.5),\n",
    "                \"train_prec\": classification.BinaryPrecision(threshold=0.5),\n",
    "                \"train_f1\": classification.BinaryF1Score(threshold=0.5),\n",
    "                \"train_mcc\": classification.BinaryMatthewsCorrCoef(threshold=0.5),\n",
    "                \"train_recall\": classification.BinaryRecall(threshold=0.5),\n",
    "                \"train_auroc\": classification.BinaryAUROC(),\n",
    "                \"train_auroc_15\": classification.BinaryAUROC(max_fpr=0.15),\n",
    "                \"train_calibration_error\": classification.BinaryCalibrationError()\n",
    "             }\n",
    "         )\n",
    "        \n",
    "        self.val_metrics = MetricCollection(\n",
    "             {\n",
    "                \"val_acc\": classification.BinaryAccuracy(threshold=0.5),\n",
    "                \"val_prec\": classification.BinaryPrecision(threshold=0.5),\n",
    "                \"val_f1\": classification.BinaryF1Score(threshold=0.5),\n",
    "                \"val_mcc\": classification.BinaryMatthewsCorrCoef(threshold=0.5),\n",
    "                \"val_recall\": classification.BinaryRecall(threshold=0.5),\n",
    "                \"val_auroc\": classification.BinaryAUROC(),\n",
    "                \"val_auroc_15\": classification.BinaryAUROC(max_fpr=0.15),\n",
    "                \"val_calibration_error\": classification.BinaryCalibrationError()\n",
    "             }\n",
    "         )\n",
    "        \n",
    "        self.test_metrics = MetricCollection(\n",
    "             {\n",
    "                \"test_acc\": classification.BinaryAccuracy(threshold=0.5),\n",
    "                \"test_prec\": classification.BinaryPrecision(threshold=0.5),\n",
    "                \"test_f1\": classification.BinaryF1Score(threshold=0.5),\n",
    "                \"test_mcc\": classification.BinaryMatthewsCorrCoef(threshold=0.5),\n",
    "                \"test_recall\": classification.BinaryRecall(threshold=0.5),\n",
    "                \"test_auroc\": classification.BinaryAUROC(),\n",
    "                \"test_auroc_15\": classification.BinaryAUROC(max_fpr=0.15),\n",
    "                \"test_calibration_error\": classification.BinaryCalibrationError()\n",
    "             }\n",
    "         )\n",
    "\n",
    "        # Predictions\n",
    "        self.test_predictions = pd.DataFrame()\n",
    "        self.predictions = pd.DataFrame()\n",
    "\n",
    "    def forward(self, x, descriptors_features):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = x.view(-1, 32*5*5)\n",
    "        mean = x.mean(dim=1, keepdim=True)\n",
    "        std = x.std(dim=1, keepdim=True)\n",
    "        descriptors_features_normalized = (descriptors_features - descriptors_features.mean(dim=0, keepdim=True)) / (descriptors_features.std(dim=0, keepdim=True) + 1e-6)\n",
    "        descriptors_features_normalized = descriptors_features_normalized * std + mean\n",
    "        x = torch.cat((x, descriptors_features_normalized), dim=1) \n",
    "        x = F.dropout(F.relu(self.fc1(x)), self.drop_rate, training = self.training)\n",
    "        x = F.dropout(F.relu(self.fc2(x)), self.drop_rate, training = self.training)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr=self.hparams.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def cross_entropy_loss(self,input,labels):\n",
    "        return F.cross_entropy(input,labels)\n",
    "    \n",
    "    def training_step(self,train_batch,batch_idx):\n",
    "        img_arrs, label, comp_id, descriptor_features = train_batch\n",
    "        y_pred = self.forward(img_arrs,descriptor_features)\n",
    "        y_pred_soft_max = F.softmax(y_pred,dim=1)\n",
    "        y_pred_soft_max_1_active = y_pred_soft_max[:,1]\n",
    "        loss = self.cross_entropy_loss(y_pred.squeeze(),label)\n",
    "        self.log('train_loss', loss, batch_size=self.hparams.batch_size, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        output = self.train_metrics(y_pred_soft_max_1_active,label.int())\n",
    "        self.log_dict(output,on_step=False,on_epoch=True, batch_size=self.hparams.batch_size, sync_dist=True)\n",
    "        \n",
    "        return loss\n",
    "      \n",
    "    def validation_step(self,val_batch,batch_idx):\n",
    "        img_arrs, label, comp_id, descriptor_features  = val_batch\n",
    "        y_pred = self.forward(img_arrs, descriptor_features)\n",
    "        y_pred_soft_max = F.softmax(y_pred,dim=1)\n",
    "        y_pred_soft_max_1_active = y_pred_soft_max[:,1]\n",
    "        loss = self.cross_entropy_loss(y_pred.squeeze(),label)\n",
    "        self.log('val_loss', loss, batch_size=self.hparams.batch_size, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        output = self.val_metrics(y_pred_soft_max_1_active,label.int())\n",
    "        self.log_dict(output,on_step=False,on_epoch=True,batch_size=self.hparams.batch_size,  sync_dist=True)\n",
    "\n",
    "    def test_step(self,test_batch,batch_idx):\n",
    "        img_arrs, label, comp_id, descriptor_features = test_batch\n",
    "        y_pred = self.forward(img_arrs, descriptor_features)\n",
    "        _, preds = torch.max(y_pred,1)\n",
    "        y_pred_soft_max = F.softmax(y_pred,dim=1)\n",
    "        y_pred_soft_max_1_active = y_pred_soft_max[:,1]\n",
    "        loss = self.cross_entropy_loss(y_pred.squeeze(),label)\n",
    "        self.log('test_loss', loss, batch_size=self.hparams.batch_size, prog_bar=True)\n",
    "\n",
    "        output = self.test_metrics(y_pred_soft_max_1_active,label.int())\n",
    "        self.log_dict(output,on_step=False,on_epoch=True,batch_size=self.hparams.batch_size)\n",
    "\n",
    "        comp_id_pd = pd.Series(comp_id,name=\"comp_id\")\n",
    "        label_pd = pd.Series(label.cpu(),name=\"label\")\n",
    "        pred_pd = pd.Series(preds.cpu(),name=\"prediction\")\n",
    "        pred_0_pd = pd.Series(y_pred_soft_max[:,0].cpu(),name=\"0_inactive_probability\")\n",
    "        pred_1_pd = pd.Series(y_pred_soft_max[:,1].cpu(),name=\"1_active_probability\")\n",
    "        batch_predictions = pd.concat([comp_id_pd,label_pd,pred_pd,pred_0_pd,pred_1_pd],axis=1)\n",
    "        self.test_predictions = pd.concat([self.test_predictions,batch_predictions],axis=0)\n",
    "\n",
    "    def on_test_end(self):\n",
    "        self.test_predictions.to_csv(os.path.join(self.hparams.experiment_result_path,f\"test_{self.hparams.target}_{self.hparams.fully_layer_1}-{self.hparams.fully_layer_2}-{self.hparams.learning_rate}-{self.hparams.drop_rate}-{self.hparams.batch_size}.csv\"),index=False)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        img_arrs, comp_id, descriptor_features = batch\n",
    "        y_pred = self.forward(img_arrs, descriptor_features)\n",
    "        _, preds = torch.max(y_pred,1)\n",
    "        comp_id_pd = pd.Series(comp_id,name=\"comp_id\")\n",
    "        pred_pd = pd.Series(preds.cpu(),name=\"prediction\")\n",
    "        y_pred_soft_max = F.softmax(y_pred,dim=1) \n",
    "        pred_0_pd = pd.Series(y_pred_soft_max[:,0].cpu(),name=\"0_inactive_probability\")\n",
    "        pred_1_pd = pd.Series(y_pred_soft_max[:,1].cpu(),name=\"1_active_probability\")\n",
    "        batch_predictions = pd.concat([comp_id_pd,pred_pd,pred_0_pd,pred_1_pd],axis=1)\n",
    "        self.predictions = pd.concat([self.predictions,batch_predictions],axis=0)\n",
    "        return batch_predictions\n",
    "\n",
    "    def on_predict_epoch_end(self):\n",
    "        return self.predictions\n",
    "    \n",
    "    def on_predict_end(self):\n",
    "        self.predictions.to_csv(os.path.join(self.hparams.experiment_result_path,f\"predictions_{self.hparams.target}_{self.hparams.fully_layer_1}-{self.hparams.fully_layer_2}-{self.hparams.learning_rate}-{self.hparams.drop_rate}-{self.hparams.batch_size}.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/sjinich/disco/che_env/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "# External imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from rdkit.Chem import Draw, MolFromSmiles\n",
    "import re\n",
    "import deepchem as dc\n",
    "\n",
    "# Internal Imports\n",
    "from utils.constants import RANDOM_STATE\n",
    "from utils.logging_deepscreen import logger\n",
    "from utils.configurations import configs\n",
    "\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "class DEEPScreenDataset(Dataset):\n",
    "    def __init__(self, path_imgs_files:str, df_compid_smiles_bioactivity:pd.DataFrame):\n",
    "            super(DEEPScreenDataset, self).__init__()\n",
    "\n",
    "            self.path_imgs = path_imgs_files\n",
    "            self.df = df_compid_smiles_bioactivity.copy()\n",
    "            self.config = configs\n",
    "\n",
    "            if not os.path.exists(self.path_imgs):\n",
    "                os.makedirs(self.path_imgs)\n",
    "\n",
    "            # creating molecules images -> path will be stored in 'img_molecule' column\n",
    "            self.df['img_molecule'] = self.df.apply(lambda x: self.smiles_to_img_png(x[\"comp_id\"],x[\"smiles\"],self.path_imgs),axis=1)\n",
    "\n",
    "            featurizer = dc.feat.RDKitDescriptors()\n",
    "            features = featurizer.featurize(self.df[\"smiles\"])\n",
    "            descriptors_rdkit = pd.Series([torch.tensor(tensor).type(torch.FloatTensor) for tensor in features], name=\"descriptor_features\")\n",
    "            self.df = pd.concat([self.df,descriptors_rdkit],axis=1)\n",
    "\n",
    "            logger.debug(f'Dataset created in {self.path_imgs}')\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def smiles_to_img_png(self, comp_id:str, smiles:str, output_path:str)->str:\n",
    "        '''\n",
    "        Given an id and an output path the function will create a image with the 2D molecule. \n",
    "\n",
    "        Returns: the path to the file i.e. /output_path/comp_id.png\n",
    "        '''\n",
    "        mol = MolFromSmiles(smiles)\n",
    "        opt = self.config.get_mol_draw_options()\n",
    "        img_size = self.config.get_img_size()\n",
    "        comp_id_clean = re.sub('[^A-Za-z0-9]+', '_', comp_id)\n",
    "\n",
    "        output_file = os.path.join(output_path, f\"{comp_id_clean}.png\")\n",
    "        Draw.MolToFile(mol, output_file, size=img_size, options=opt)\n",
    "        return output_file\n",
    "\n",
    "\n",
    "class DEEPScreenDatasetPredict(DEEPScreenDataset):\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        comp_id = row[\"comp_id\"]\n",
    "        img_path = row['img_molecule']\n",
    "        features = row[\"descriptor_features\"]\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = np.array(img_arr) / 255.0\n",
    "        img_arr = img_arr.transpose((2, 0, 1))\n",
    "        return torch.tensor(img_arr).type(torch.FloatTensor), comp_id, features\n",
    "    \n",
    "\n",
    "class DEEPScreenDatasetTrain(DEEPScreenDataset):\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        comp_id = row[\"comp_id\"]\n",
    "        img_path = row['img_molecule']\n",
    "        features = row[\"descriptor_features\"]\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        if random.random()>=0.50:\n",
    "            angle = random.randint(0,359)\n",
    "            rows, cols, channel = img_arr.shape\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "            img_arr = cv2.warpAffine(img_arr, rotation_matrix, (cols, rows), cv2.INTER_LINEAR,\n",
    "                                             borderValue=(255, 255, 255))  # cv2.BORDER_CONSTANT, 255)\n",
    "        img_arr = np.array(img_arr) / 255.0\n",
    "        img_arr = img_arr.transpose((2, 0, 1))\n",
    "        label = row[\"bioactivity\"]\n",
    "\n",
    "        return torch.tensor(img_arr).type(torch.FloatTensor), torch.tensor(label).type(torch.LongTensor), comp_id, features\n",
    "    \n",
    "\n",
    "class DEEPScreenDatasetTest(DEEPScreenDataset):\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        comp_id = row[\"comp_id\"]\n",
    "        img_path = row['img_molecule']\n",
    "        features = row[\"descriptor_features\"]\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = np.array(img_arr) / 255.0\n",
    "        img_arr = img_arr.transpose((2, 0, 1))\n",
    "        label = row[\"bioactivity\"]\n",
    "\n",
    "        return torch.tensor(img_arr).type(torch.FloatTensor), torch.tensor(label).type(torch.LongTensor), comp_id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External imports\n",
    "import lightning as L\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import tempfile\n",
    "\n",
    "# Internal imports\n",
    "from utils.logging_deepscreen import logger\n",
    "from utils.exceptions import InvalidDataframeException\n",
    "from utils.configurations import configs\n",
    "\n",
    "\n",
    "class DEEPscreenDataModule(L.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, data:str, batch_size:int, experiment_result_path:str, data_split_mode:str, tmp_imgs:bool = False):\n",
    "\n",
    "        super(DEEPscreenDataModule, self).__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "        self.result_path = experiment_result_path\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if tmp_imgs:\n",
    "            self.imgs_path = tempfile.TemporaryDirectory().name\n",
    "        else:\n",
    "            self.imgs_path = os.path.join(self.result_path,\"imgs\")\n",
    "        \n",
    "        if data_split_mode in (\"random_split\",\"non_random_split\",\"scaffold_split\",\"predict\"):\n",
    "            self.data_split = data_split_mode\n",
    "        else:\n",
    "            raise Exception(\"data split mode should be one of random_split/non_random_split/scaffold_split/predict\")\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        if data_split_mode != \"predict\" and not {\"comp_id\",\"smiles\",\"bioactivity\"}.issubset(set(self.data.columns)):\n",
    "            logger.error(\"invalid columns of df\")\n",
    "            raise InvalidDataframeException(\"must contain the following columns {'comp_id','smiles','bioactivity'}\")\n",
    "\n",
    "    def setup(self,stage:str):\n",
    "        \n",
    "        # cleaning data to prune posible errors\n",
    "        self.data = self.data.dropna(how=\"any\")\n",
    "\n",
    "        logger.info(f\"Using a total of {len(self.data)} datapoints\")\n",
    "\n",
    "        if stage == \"fit\" or stage == \"test\" or stage == \"validation\":\n",
    "\n",
    "            # sanitizeing data\n",
    "            self.data[\"bioactivity\"] = self.data[\"bioactivity\"].astype(int)\n",
    "\n",
    "            if self.data_split == \"random_split\":\n",
    "                #TODO\n",
    "                raise NotImplementedError\n",
    "\n",
    "            if self.data_split == \"non_random_split\":\n",
    "                dataset = self._non_random_split(self.data)\n",
    "                self.train = dataset[\"train\"]\n",
    "                self.validate = dataset[\"validation\"]\n",
    "                self.test = dataset[\"test\"]\n",
    "\n",
    "            if self.data_split == \"scaffold_split\":\n",
    "                #TODO\n",
    "                raise NotImplementedError\n",
    "            \n",
    "        \n",
    "        if stage == \"predict\":\n",
    "            self.predict = self.data\n",
    "    \n",
    "    def get_number_training_batches(self):\n",
    "        if self.data_split == \"non_random_split\":\n",
    "            number_training_batches = round(len(self.data[self.data[\"data_split\"] == \"train\"])/self.batch_size)\n",
    "        else:\n",
    "            number_training_batches = 50\n",
    "            \n",
    "        return number_training_batches\n",
    "    \n",
    "    def _non_random_split(self,data):\n",
    "        if \"data_split\" not in data.columns:\n",
    "            logger.error(\"theres not a 'data_split' column in the dataframe for non random datasplit\")\n",
    "            raise InvalidDataframeException(\"Missing 'data_split' column while using non_random_split\")\n",
    "\n",
    "        if not set(data[\"data_split\"].unique()).issubset({\"train\",\"validation\",\"test\",\"predict\"}):\n",
    "            logger.error(\"invalid tags or missing tags for data spliting in non random datasplit\")\n",
    "            raise InvalidDataframeException(\"Invalid tags or missing tags for data spliting in non random datasplit, tags should be in ('trian','validation','test','predict')\")\n",
    "        \n",
    "        dataset = {\"train\":None,\"validation\":None,\"test\":None}\n",
    "        \n",
    "        try:\n",
    "            for key in data[\"data_split\"].unique():\n",
    "                dataset[key] = data[data[\"data_split\"]==key]\n",
    "                logger.info(f\"non_random_split dataset splited {key}={len(dataset[key])}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unable to create non_random_split datasets {e}\")\n",
    "            raise RuntimeError(\"non_random_split dataloader type generator failed\")\n",
    "\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.training_dataset = DEEPScreenDatasetTrain(self.imgs_path, self.train)\n",
    "        return DataLoader(self.training_dataset,batch_size=self.hparams.batch_size,shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        self.validation_dataset = DEEPScreenDatasetTest(self.imgs_path, self.validate)\n",
    "        return DataLoader(self.validation_dataset,batch_size=self.hparams.batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        self.test_dataset = DEEPScreenDatasetTest(self.imgs_path, self.test)\n",
    "        return DataLoader(self.test_dataset,batch_size=self.hparams.batch_size)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        self.predict_dataset = DEEPScreenDatasetPredict(self.imgs_path, self.predict)\n",
    "        return DataLoader(self.predict_dataset,batch_size=self.hparams.batch_size)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/sjinich/disco/TrypanoDEEPscreen/.data/processed/CHEMBL2581.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using hyperparameters [('fully_layer_1', 256), ('fully_layer_2', 32), ('drop_rate', 0.5), ('learning_rate', 0.0001), ('batch_size', 32), ('experiment_result_path', '../../.experiments/chembl2581'), ('target', 'CHEMBL2581')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using a total of 2270 datapoints\n",
      "INFO: non_random_split dataset splited validation=364\n",
      "INFO: non_random_split dataset splited train=1452\n",
      "INFO: non_random_split dataset splited test=454\n",
      "\n",
      "   | Name          | Type             | Params\n",
      "----------------------------------------------------\n",
      "0  | conv1         | Conv2d           | 416   \n",
      "1  | bn1           | BatchNorm2d      | 64    \n",
      "2  | conv2         | Conv2d           | 8.3 K \n",
      "3  | bn2           | BatchNorm2d      | 128   \n",
      "4  | conv3         | Conv2d           | 32.9 K\n",
      "5  | bn3           | BatchNorm2d      | 256   \n",
      "6  | conv4         | Conv2d           | 32.8 K\n",
      "7  | bn4           | BatchNorm2d      | 128   \n",
      "8  | conv5         | Conv2d           | 8.2 K \n",
      "9  | bn5           | BatchNorm2d      | 64    \n",
      "10 | pool          | MaxPool2d        | 0     \n",
      "11 | fc1           | Linear           | 258 K \n",
      "12 | fc2           | Linear           | 8.2 K \n",
      "13 | fc3           | Linear           | 66    \n",
      "14 | train_metrics | MetricCollection | 0     \n",
      "15 | val_metrics   | MetricCollection | 0     \n",
      "16 | test_metrics  | MetricCollection | 0     \n",
      "----------------------------------------------------\n",
      "350 K     Trainable params\n",
      "0         Non-trainable params\n",
      "350 K     Total params\n",
      "1.401     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjinich/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 800 but got size 210 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m DEEPScreenClassifier(fully_layer_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,fully_layer_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,drop_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,experiment_result_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../.experiments/chembl2581\u001b[39m\u001b[38;5;124m\"\u001b[39m,target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHEMBL2581\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m DEEPscreenDataModule(data\u001b[38;5;241m=\u001b[39mdf,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,experiment_result_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../.experiments/chembl2581\u001b[39m\u001b[38;5;124m\"\u001b[39m,data_split_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_random_split\u001b[39m\u001b[38;5;124m\"\u001b[39m,tmp_imgs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    577\u001b[0m     ckpt_path,\n\u001b[1;32m    578\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m )\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 990\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    995\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:1034\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1034\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1036\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:1063\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1060\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 124\u001b[0m, in \u001b[0;36mDEEPScreenClassifier.validation_step\u001b[0;34m(self, val_batch, batch_idx)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m,val_batch,batch_idx):\n\u001b[1;32m    123\u001b[0m     img_arrs, label, comp_id, descriptor_features  \u001b[38;5;241m=\u001b[39m val_batch\n\u001b[0;32m--> 124\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_arrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptor_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     y_pred_soft_max \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(y_pred,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    126\u001b[0m     y_pred_soft_max_1_active \u001b[38;5;241m=\u001b[39m y_pred_soft_max[:,\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[1], line 96\u001b[0m, in \u001b[0;36mDEEPScreenClassifier.forward\u001b[0;34m(self, x, descriptors_features)\u001b[0m\n\u001b[1;32m     94\u001b[0m descriptors_features_normalized \u001b[38;5;241m=\u001b[39m (descriptors_features \u001b[38;5;241m-\u001b[39m descriptors_features\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;241m/\u001b[39m (descriptors_features\u001b[38;5;241m.\u001b[39mstd(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m     95\u001b[0m descriptors_features_normalized \u001b[38;5;241m=\u001b[39m descriptors_features_normalized \u001b[38;5;241m*\u001b[39m std \u001b[38;5;241m+\u001b[39m mean\n\u001b[0;32m---> 96\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptors_features_normalized\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     97\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     98\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 800 but got size 210 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=100)\n",
    "model = DEEPScreenClassifier(fully_layer_1=256,fully_layer_2=32,drop_rate=0.5,learning_rate=0.0001,batch_size=32,experiment_result_path=\"../../.experiments/chembl2581\",target=\"CHEMBL2581\")\n",
    "datamodule = DEEPscreenDataModule(data=df,batch_size=32,experiment_result_path=\"../../.experiments/chembl2581\",data_split_mode=\"non_random_split\",tmp_imgs=True)\n",
    "trainer.fit(model,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206608/2513407159.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  tensor = torch.tensor([img_arr]).type(torch.FloatTensor)\n",
      "INFO: Using hyperparameters [('fully_layer_1', 512), ('fully_layer_2', 256), ('drop_rate', 0.001), ('learning_rate', 0.3), ('batch_size', 32), ('experiment_result_path', '/home/sjinich/disco/TrypanoDEEPscreen/.experiments/trial_adding_vector'), ('target', 'trial_adding_tensor')]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([img_arr])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\n\u001b[1;32m     12\u001b[0m network \u001b[38;5;241m=\u001b[39m DEEPScreenClassifier(\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;241m0.3\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/sjinich/disco/TrypanoDEEPscreen/.experiments/trial_adding_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial_adding_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m otuput, lineal_tensor \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mforward(tensor, \u001b[43mdf_d\u001b[49m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescriptor_features\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_d' is not defined"
     ]
    }
   ],
   "source": [
    "img_arr = cv2.imread(\"/home/sjinich/disco/TrypanoDEEPscreen/.experiments/imgs/2_Deoxy_2_methyl_nitroso_carbamoyl_amino_hexose.png\")\n",
    "if random.random()>=0:\n",
    "    angle = random.randint(0,359)\n",
    "    rows, cols, channel = img_arr.shape\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    img_arr = cv2.warpAffine(img_arr, rotation_matrix, (cols, rows), cv2.INTER_LINEAR,\n",
    "                                     borderValue=(255, 255, 255))  # cv2.BORDER_CONSTANT, 255)\n",
    "img_arr = np.array(img_arr) / 255.0\n",
    "img_arr = img_arr.transpose((2, 0, 1))\n",
    "tensor = torch.tensor([img_arr]).type(torch.FloatTensor)\n",
    "\n",
    "network = DEEPScreenClassifier(512,256,0.001,0.3,32,\"/home/sjinich/disco/TrypanoDEEPscreen/.experiments/trial_adding_vector\",\"trial_adding_tensor\")\n",
    "\n",
    "otuput, lineal_tensor = network.forward(tensor, df_d.loc[0,\"descriptor_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0088, 0.1532], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otuput.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.RDKitDescriptors()\n",
    "features = featurizer.featurize(df[\"smiles\"])\n",
    "descriptors_rdkit = pd.Series([torch.tensor(tensor).type(torch.FloatTensor) for tensor in features], name=\"descriptor_features\")\n",
    "df = pd.concat([df,descriptors_rdkit],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4299e+01,  1.4299e+01,  2.0595e-02, -1.5042e+00,  7.5694e-02,\n",
       "         1.3786e+01,  7.6595e+02,  7.1051e+02,  7.6541e+02,  2.9800e+02,\n",
       "         0.0000e+00,  4.0763e-01, -4.9677e-01,  4.9677e-01,  4.0763e-01,\n",
       "         5.7143e-01,  1.0714e+00,  1.6250e+00,  1.6548e+01,  9.9325e+00,\n",
       "         2.3755e+00, -2.3335e+00,  2.1566e+00, -2.6294e+00,  5.9045e+00,\n",
       "        -1.3356e-01,  3.2064e+00,  1.5823e+00,  1.8082e+03,  4.0451e+01,\n",
       "         3.2736e+01,  3.2736e+01,  2.6943e+01,  1.8926e+01,  1.8926e+01,\n",
       "         1.4363e+01,  1.4363e+01,  9.3392e+00,  9.3392e+00,  6.0694e+00,\n",
       "         6.0694e+00, -5.7200e+00,  3.2064e+00,  4.3014e+01,  2.1987e+01,\n",
       "         1.3540e+01,  3.2932e+02,  3.5847e+01,  3.0482e+01,  0.0000e+00,\n",
       "         1.7722e+01,  0.0000e+00,  6.0932e+00,  1.9700e+01,  4.7945e+00,\n",
       "         0.0000e+00,  0.0000e+00,  1.3082e+02,  5.2643e+01,  1.3090e+01,\n",
       "         1.9256e+01,  3.3758e+01,  2.3815e+01,  0.0000e+00,  2.6584e+01,\n",
       "         1.1836e+01,  8.4083e+01,  7.1098e+00,  1.3751e+02,  0.0000e+00,\n",
       "         5.7495e+00,  3.1321e+01,  4.7945e+00,  5.7495e+00,  0.0000e+00,\n",
       "         6.6302e+01,  4.5238e+01,  1.1836e+01,  4.9949e+01,  1.1526e+02,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.6712e+02,  4.8179e+01,\n",
       "         2.4285e+01,  0.0000e+00,  4.3860e+01,  5.7495e+00,  2.2254e+01,\n",
       "         0.0000e+00,  3.3090e+01,  1.1698e+02,  2.6584e+01,  9.4737e+00,\n",
       "         1.0690e+01,  0.0000e+00,  5.4654e+01,  2.6783e+01,  3.2942e+00,\n",
       "        -1.5658e+00,  3.0856e+01, -2.1270e+00,  7.6800e+00,  1.5688e+00,\n",
       "         3.6364e-01,  5.6000e+01,  6.0000e+00,  1.2000e+01,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  4.0000e+00,  0.0000e+00,  4.0000e+00,\n",
       "         8.0000e+00,  6.0000e+00,  1.2000e+01,  2.0000e+01,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  4.0000e+00,  4.6500e+00,  2.1515e+02,\n",
       "         0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         4.0000e+00,  4.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  5.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  4.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  2.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"descriptor_features\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
