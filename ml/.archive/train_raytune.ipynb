{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjinich/disco/che_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-29 13:22:13,721\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-02-29 13:22:13,883\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-02-29 13:22:15,651\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from engine.hyperparameters_tune_raytune import deepscreen_hyperparameter_tuneing\n",
    "from utils.configurations import configs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-02-29 13:33:22</td></tr>\n",
       "<tr><td>Running for: </td><td>00:11:02.41        </td></tr>\n",
       "<tr><td>Memory:      </td><td>30.0/503.8 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 3.000: -0.018914880231022835 | Iter 1.000: 0.31670167048772174<br>Logical resource usage: 2.0/48 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">   train_loop_config/ba\n",
       "tch_size</th><th style=\"text-align: right;\">    train_loop_config/dr\n",
       "op_rate</th><th style=\"text-align: right;\">    train_loop_config/fu\n",
       "lly_layer_1</th><th style=\"text-align: right;\">    train_loop_config/fu\n",
       "lly_layer_2</th><th style=\"text-align: right;\">       train_loop_config/le\n",
       "arning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  val_acc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_90bca_00000</td><td>TERMINATED</td><td>10.1.103.91:1838391</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.005 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         658.227</td><td style=\"text-align: right;\">    1.03522 </td><td style=\"text-align: right;\"> 11.7601  </td><td style=\"text-align: right;\"> 0.376374</td></tr>\n",
       "<tr><td>TorchTrainer_90bca_00001</td><td>TERMINATED</td><td>10.1.103.91:1838392</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\"> 32</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         341.64 </td><td style=\"text-align: right;\">    0.593602</td><td style=\"text-align: right;\">  0.634111</td><td style=\"text-align: right;\"> 0.618132</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TorchTrainer pid=1838392)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=1838392)\u001b[0m - (ip=10.1.103.91, pid=1838584) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m INFO: Using hyperparameters [('fully_layer_1', 256), ('fully_layer_2', 32), ('drop_rate', 0.5), ('learning_rate', 0.0001), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/chembl2581_trial'), ('temperature_scaleing', 1)]\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m GPU available: False, used: False\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m [rank: 0] Seed set to 123\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m Missing logger folder: /home/sjinich/ray_results/TorchTrainer_2024-02-29_13-22-15/TorchTrainer_90bca_00001_1_batch_size=32,drop_rate=0.5000,fully_layer_1=256,fully_layer_2=32,learning_rate=0.0001_2024-02-29_13-22-19/lightning_logs\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m INFO: Using a total of 2270 datapoints\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m INFO: non_random_split datasets splited train=1452,validation=364,test=454\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m /home/sjinich/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(RayTrainWorker pid=1838584)\u001b[0m /home/sjinich/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(TorchTrainer pid=1838391)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=1838391)\u001b[0m - (ip=10.1.103.91, pid=1838583) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m INFO: Using hyperparameters [('fully_layer_1', 128), ('fully_layer_2', 512), ('drop_rate', 0.5), ('learning_rate', 0.005), ('batch_size', 32), ('experiment_result_path', '/big/lab/sjinich/TrypanoDEEPscreen/.experiments/chembl2581_trial'), ('temperature_scaleing', 1)]\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m GPU available: False, used: False\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m [rank: 0] Seed set to 123\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m Missing logger folder: /home/sjinich/ray_results/TorchTrainer_2024-02-29_13-22-15/TorchTrainer_90bca_00000_0_batch_size=32,drop_rate=0.5000,fully_layer_1=128,fully_layer_2=512,learning_rate=0.0050_2024-02-29_13-22-19/lightning_logs\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m INFO: Using a total of 2270 datapoints\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m INFO: non_random_split datasets splited train=1452,validation=364,test=454\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m /home/sjinich/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/sjinich/ray_results/TorchTrainer_2024-02-29_13-22-15/TorchTrainer_90bca_00000_0_batch_size=32,drop_rate=0.5000,fully_layer_1=128,fully_layer_2=512,learning_rate=0.0050_2024-02-29_13-22-19/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m /home/sjinich/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/sjinich/ray_results/TorchTrainer_2024-02-29_13-22-15/TorchTrainer_90bca_00000_0_batch_size=32,drop_rate=0.5000,fully_layer_1=128,fully_layer_2=512,learning_rate=0.0050_2024-02-29_13-22-19/checkpoint_000001)\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/sjinich/ray_results/TorchTrainer_2024-02-29_13-22-15/TorchTrainer_90bca_00000_0_batch_size=32,drop_rate=0.5000,fully_layer_1=128,fully_layer_2=512,learning_rate=0.0050_2024-02-29_13-22-19/checkpoint_000002)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/sjinich/ray_results/TorchTrainer_2024-02-29_13-22-15/TorchTrainer_90bca_00000_0_batch_size=32,drop_rate=0.5000,fully_layer_1=128,fully_layer_2=512,learning_rate=0.0050_2024-02-29_13-22-19/checkpoint_000003)\n",
      "\u001b[36m(RayTrainWorker pid=1838583)\u001b[0m `Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "2024-02-29 13:33:22,262\tINFO tune.py:1042 -- Total run time: 662.47 seconds (662.41 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argumen*\")\n",
    "\n",
    "data = pd.read_csv(\"/home/sjinich/disco/TrypanoDEEPscreen/.data/processed/CHEMBL2581.csv\")\n",
    "    \n",
    "search_space_deepscreen = configs.get_hyperparameters_search()\n",
    "\n",
    "tuner = deepscreen_hyperparameter_tuneing(\n",
    "    data=data,\n",
    "    data_split_mode=\"non_random_split\",\n",
    "    search_space=search_space_deepscreen,\n",
    "    target=\"chembl2581_trial\",\n",
    "    experiments_result_path=\"../../.experiments\",\n",
    "    **configs.get_hyperparameters_search_setup()\n",
    "    )\n",
    "\n",
    "result = tuner.tune_deepscreen()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6341113448143005,\n",
       " 'val_acc': 0.6181318759918213,\n",
       " 'val_auroc': 0.7709251046180725,\n",
       " 'val_auroc_15': 0.5830983519554138,\n",
       " 'val_calibration_error': 0.16824299097061157,\n",
       " 'val_f1': 0.627345860004425,\n",
       " 'val_mcc': 0.30024105310440063,\n",
       " 'val_prec': 0.801369845867157,\n",
       " 'val_recall': 0.515418529510498}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmet = result.get_best_result(metric=\"val_mcc\",mode=\"max\").metrics\n",
    "{i:j for i,j in bestmet.items() if i.find(\"val\") != -1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(result.get_best_result(metric=\"val_mcc\",mode=\"max\").checkpoint.path,\"checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using hyperparameters [('fully_layer_1', 256), ('fully_layer_2', 32), ('drop_rate', 0.5), ('learning_rate', 0.0001), ('batch_size', 32), ('experiment_result_path', '../../.experiments/chembl2581'), ('temperature_scaleing', 1)]\n"
     ]
    }
   ],
   "source": [
    "from engine.system import DEEPScreenClassifier\n",
    "from datasets.datamodule import DEEPscreenDataModule\n",
    "\n",
    "model = DEEPScreenClassifier.load_from_checkpoint(ckpt_dir,experiment_result_path=\"../../.experiments/chembl2581\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hparams_type'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.CHECKPOINT_HYPER_PARAMS_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../.data/processed/CHEMBL2581.csv\")\n",
    "datamodule = DEEPscreenDataModule(data=data,target_id=\"CHEMBL2581\",batch_size=32,experiment_result_path=\"../../.experiments/chembl2581\",data_split_mode=\"non_random_split\",tmp_imgs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO: Using a total of 2270 datapoints\n",
      "INFO: non_random_split datasets splited train=1452,validation=364,test=454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 15/15 [00:04<00:00,  3.50it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6453744769096375\n",
      "       test_auroc           0.7404670119285583\n",
      "      test_auroc_15         0.5651069283485413\n",
      " test_calibration_error     0.15835818648338318\n",
      "         test_f1            0.6298850774765015\n",
      "        test_loss           0.6269093751907349\n",
      "        test_mcc            0.32578131556510925\n",
      "        test_prec           0.7611111402511597\n",
      "       test_recall          0.5372549295425415\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjinich/disco/che_env/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:211: You called `self.log('test_mcc', ...)` in your `test_step` but the value needs to be floating point. Converting it to torch.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6269093751907349,\n",
       "  'test_acc': 0.6453744769096375,\n",
       "  'test_auroc': 0.7404670119285583,\n",
       "  'test_auroc_15': 0.5651069283485413,\n",
       "  'test_calibration_error': 0.15835818648338318,\n",
       "  'test_f1': 0.6298850774765015,\n",
       "  'test_mcc': 0.32578131556510925,\n",
       "  'test_prec': 0.7611111402511597,\n",
       "  'test_recall': 0.5372549295425415}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "\n",
    "trainer = Trainer()\n",
    "\n",
    "trainer.test(model,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/pandas/core/indexes/range.py:345\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 2 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m result_df \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_dataframe()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresult_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/pandas/core/indexing.py:1293\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/pandas/core/generic.py:4095\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4093\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4095\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4097\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4098\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/disco/che_env/lib/python3.8/site-packages/pandas/core/indexes/range.py:347\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "result_df = result.get_dataframe()\n",
    "result_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__fspath__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_annotated',\n",
       " '_get_temporary_checkpoint_dir',\n",
       " '_uuid',\n",
       " 'as_directory',\n",
       " 'filesystem',\n",
       " 'from_directory',\n",
       " 'get_metadata',\n",
       " 'path',\n",
       " 'set_metadata',\n",
       " 'to_directory',\n",
       " 'update_metadata']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(result.get_best_result(metric=\"val_mcc\",mode=\"max\").checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fully_layer_1': 256,\n",
       " 'fully_layer_2': 32,\n",
       " 'learning_rate': 0.0001,\n",
       " 'batch_size': 32,\n",
       " 'drop_rate': 0.3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_best_result(metric=\"val_mcc\",mode=\"max\").config[\"train_loop_config\"][\"batch_size\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
